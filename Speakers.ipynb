{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1349fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from iteration_utilities import duplicates\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74adae4",
   "metadata": {},
   "source": [
    "# Functions and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04aad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFile(fileList, file): #remove file from list of files. file as string \n",
    "    if file in fileList:\n",
    "        fileList.remove(file)\n",
    "        \n",
    "    return fileList  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c719d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakerPath = \"Files/InvitedSpeakers\"\n",
    "presenterPath = \"Files/Presenters\"\n",
    "chairPath = \"Files/ChairIndex\"\n",
    "pagesPath = \"Files/Pages\"\n",
    "sessionPath = \"Files/Sessions\"\n",
    "\n",
    "speakers = removeFile(os.listdir(speakerPath), '.DS_Store') #invited speakers for 2005-2023\n",
    "presenters = removeFile(os.listdir(presenterPath),'.DS_Store')  #all presenters for 2005-2023\n",
    "chair = removeFile(os.listdir(chairPath), '.DS_Store') #chair index for 2005-2023\n",
    "pages = removeFile(os.listdir(pagesPath), '.DS_Store') #pages showing overview of sessions for 1994-2004\n",
    "sessions = removeFile(os.listdir(sessionPath), '.DS_Store') #showing overview of subsessions for 1994-2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62706c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoupFromFile(path, file): #get soup from file\n",
    "    soup = BeautifulSoup(open(path + '/' + file))\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a53174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYear(regex, file): #get year from name on file\n",
    "    year = int(re.findall(regex, file)[0])\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343053d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from the other notebook, instead of repeating it\n",
    "def getText(soup, regex, find_type, attribute): #attribute as string\n",
    "    text_list = []\n",
    "    \n",
    "    if attribute == 'text':\n",
    "        for t in soup.find_all(find_type, string = re.compile(regex, re.IGNORECASE)):\n",
    "            text_list.append(t.text)\n",
    "    else:\n",
    "        for t in soup.find_all(find_type, attrs = {attribute: re.compile(regex, re.IGNORECASE)}):\n",
    "            text_list.append(t.text)\n",
    " \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f873adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseName(name): #reverse name, so first name is first\n",
    "    if name == 'TBD, ':\n",
    "        reversedName = name\n",
    "    else:\n",
    "        nameGroup = re.findall(r'(.*), (.*) ', name)[0] #first name and last name as group\n",
    "        reversedName = nameGroup[1] + \" \" + nameGroup[0] #reverse name\n",
    "        \n",
    "    return reversedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a6fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speakerInfo(soup, year, dict_, index): #get name, university and title of invited speaker from file. Page type 1\n",
    "    speakerInfo = soup.table.findAll('tr')\n",
    "    for i in speakerInfo:\n",
    "        inv_name = i.strong.text #invited speakers\n",
    "        name = reverseName(inv_name) #name reversed, so first name is first\n",
    "        university = getText(i, r'2', 'font', 'size')[0] #university/department\n",
    "        presentationInfo = i.findAll('b')[0].text #info about presentation/abstract\n",
    "        sessionTitle = re.findall(r'Session (.*) ', presentationInfo)[0] #get sessionTitle\n",
    "        title = re.findall(r'\\n(.*)', presentationInfo)[0] #get title of presentation/article\n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university, 'Title': title, 'SessionTitle': sessionTitle}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897884c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSessionTitle(soup): #for presenter, of file type 1\n",
    "    titleText = soup.findAll('title')\n",
    "    if titleText:\n",
    "        title = re.findall(r'Event - (.*)', titleText[0].text)[0]\n",
    "    else:\n",
    "        title = 'Unknown'\n",
    "        \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c579a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringUnit(soup): #find sponsoring unit for sessions(speakers). Works for file type 1.\n",
    "    findSponsor = soup.find(string = re.compile(r'Sponsoring'))  #compile sponsor\n",
    "    if findSponsor:\n",
    "        sponsor = re.findall(r':.*\\n(.*)', findSponsor)[0]\n",
    "    else:\n",
    "        sponsor = 'None'\n",
    "    return sponsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39039257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringDict(soup, year, dict_, index): #get sponsoring unit as dict\n",
    "    linkText = soup.find_all('a') #find text about link\n",
    "    for t in linkText:\n",
    "        sponsor = re.findall(r'\\n (.*):', t.previous)\n",
    "        if sponsor:\n",
    "            sponsoringUnit = sponsor[0]\n",
    "            session = re.findall(r'Session (.*).', t.previous.previous)[0]\n",
    " \n",
    "        else:\n",
    "            sponsoringUnit = 'None'\n",
    "            session = 'Unknown'\n",
    "        \n",
    "        dict_[index] = {'Year': year, 'SessionTitle': session, 'SponsoringUnit': sponsoringUnit}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92dbcc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findText(soup, findType, attribute): #attribute as dict. Get text base on findType and attribute\n",
    "    text = soup.findAll(findType, attrs = attribute)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6138b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbstractInfo(soup): #for file type 1. Get name for presentation/abstract\n",
    "    abstractInfo = soup.findAll('h3')\n",
    "    if abstractInfo:\n",
    "        for i in abstractInfo:\n",
    "            if i.next == 'Abstract: ':\n",
    "                sessionTitle = i.next.next.text\n",
    "            else: \n",
    "                sessionTitle = \"Not found\"\n",
    "    else:\n",
    "        sessionTitle = \"Not found\"\n",
    "    return sessionTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e2412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresenterInfo(soup, year, dict_, index, sessionIndex): #get info from presenter and session, page type 1\n",
    "    names = [] #for all names found\n",
    "    #authors = [] #for saving authors\n",
    "    authorCount = 0\n",
    "    title = getSessionTitle(soup) #get title of session\n",
    "    presenterInfo = findText(soup, 'span', {'class': 'largernormal'}) #get presenterInfo\n",
    "    sessionTitle = getAbstractInfo(soup)\n",
    "    sponsoringUnit = getSponsoringUnit(soup)\n",
    "    for i in presenterInfo:\n",
    "        name = i.text\n",
    "        author = re.findall(r'^\\n(.*)\\n', name)[0]\n",
    "        if author:\n",
    "            authorCount += 1\n",
    "            uniName = re.findall(r'\\((.*)\\)', name)\n",
    "            if not uniName:\n",
    "                university = 'Unknown'\n",
    "            else:\n",
    "                university = uniName[0]\n",
    "            #authors.append(author)\n",
    "            \n",
    "            dict_[index] = {'Year': year, 'Name': author, 'University': university, 'AuthorIndex': authorCount, \n",
    "                            'Title': title, 'SponsoringUnit': sponsoringUnit, 'SessionTitle': sessionTitle, 'SessionIndex': sessionIndex}\n",
    "            index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2a5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitName(nameInfo, splitBy): #splits names into name and university\n",
    "    nameSplit = nameInfo.split(splitBy)\n",
    "    name = nameSplit[0]\n",
    "    if len(nameSplit) == 2: #if name and university is written\n",
    "        university = nameSplit[1]\n",
    "        university = re.sub(r' \\xa0', r'', university)\n",
    "        university = re.sub(r' \\)', r'', university)\n",
    "    else:\n",
    "        university = 'Unknown'\n",
    "    \n",
    "    return name, university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1c0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkString(string, regex):\n",
    "    if re.findall(regex, string):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e932f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNames(nameList): #check if string is a name\n",
    "    names = []\n",
    "    for n in nameList:\n",
    "        name = n.get_text()\n",
    "        if name != '' and name != 'both' and name != 'smaller':\n",
    "            if not checkString(name, r'session') and not checkString(name, r'Room') and not checkString(name, r'\\[.*\\]') and not checkString(name, r'\\n\\n'):\n",
    "                names.append(n)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b79183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTitle(titleString): #check if string is title, and return title and whether it's a title or not\n",
    "    title = re.findall(r'\\[.*\\] (.*)', titleString)\n",
    "    if title: #check if there is a title\n",
    "        if title[0] != 'Break': #if title isn't break\n",
    "            return True, title[0]\n",
    "        else:\n",
    "            return False, title\n",
    "    else:\n",
    "        return False, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539f84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkUniversity(string): #check if string includes university (if it is inside pharanthesis)\n",
    "    if re.findall('\\(.*\\)', string):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e2ac2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameInfo(string): #return university and name from string (if university is inside pharanthesis)\n",
    "    university = re.findall(r'\\((.*)\\)', string)[0]\n",
    "    name = re.findall(r'(.*)\\(', string)[0]\n",
    "    name = re.sub(' ', '', name)\n",
    "\n",
    "    return university, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da31deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUni_and_Name(string):\n",
    "    nameInfo = []\n",
    "    names = re.split(r',\\s*(?![^()]*\\))', string)\n",
    "    \n",
    "    noUniversity = [] \n",
    "    universityList = []\n",
    "    \n",
    "    for i in names: #loop through all names\n",
    "        if checkUniversity(i): #if name is together with a university\n",
    "            university, name = getNameInfo(i) #get name and university\n",
    "            nameInfo.append((name, university)) #add name and university to set\n",
    "            \n",
    "            universityList.extend(repeat(university, len(noUniversity))) #append university the number of times, a name don't have a university\n",
    "            noUniInfo = list(zip(noUniversity, universityList)) #assign name without university to university\n",
    "            nameInfo += noUniInfo #add name and university to list\n",
    "            \n",
    "            noUniversity = [] #reset names without university\n",
    "            \n",
    "        else:\n",
    "            noUniversity.append(i)\n",
    "            \n",
    "    return nameInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "687b5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakers(fileList, path, yearRegex): #get invited speakers to dict(with their info). Page type 1\n",
    "    speaker_dict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in fileList:\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        speaker_dict, index  = speakerInfo(soup, year, speaker_dict, index)\n",
    "        \n",
    "    return speaker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100ac456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresenters(fileList, path, yearRegex): #page type 1\n",
    "    presenter_dict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in tqdm(fileList):\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        presenter_dict, index = getPresenterInfo(soup, year, presenter_dict, index,  sessIndex)\n",
    "        sessIndex += 1\n",
    "        \n",
    "    return presenter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f92d6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChairIndex1(soup, year, dict_, index):#for file type 1\n",
    "    chairNames = findText(soup, 'td', {'align': None, 'valign': 'top'})\n",
    "    for n in chairNames:\n",
    "        name, university = splitName(n.text, ',')\n",
    "        \n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university} #add year, name and university to dictionary\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93f745fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getChairIndex2(soup, year, dict_, index):#for file type 2\n",
    "def getChairIndex2(soup, year, dict_, index):#for file type 2\n",
    "    chairNames = re.findall(r'Chair: (.*)', str(soup))\n",
    "    for n in chairNames:\n",
    "        name, university = splitName(n, ',')\n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ebae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChair(fileList1, fileList2, path1, path2, yearRegex1, yearRegex2): #get chairIndex for type 1 and 2 files\n",
    "    chair_dict = {}\n",
    "    index = 0\n",
    "    for file in fileList1:\n",
    "        soup = getSoupFromFile(path1, file)\n",
    "        year = getYear(yearRegex1, file)\n",
    "        chair_dict, index = getChairIndex1(soup, year, chair_dict, index)\n",
    "    \n",
    "    for file in fileList2:\n",
    "        soup = getSoupFromFile(path2, file)\n",
    "        year = getYear(yearRegex2, file)\n",
    "        chair_dict, index = getChairIndex2(soup, year, chair_dict, index)\n",
    "    \n",
    "    return chair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9f73896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSessionType(info): #get session type\n",
    "    sessionType = re.findall(r'<i>(.*) session', str(info))[0].lower()\n",
    "    \n",
    "    return sessionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0af84139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringUnit_pages(fileList, path, yearRegex): #get sponsoring unit for file type 2, from pages\n",
    "    sponsoringDict = {}\n",
    "    index = 0\n",
    "    for file in tqdm(fileList): \n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        speaker_dict, index  = getSponsoringDict(soup, year, sponsoringDict, index)\n",
    "    \n",
    "    return sponsoringDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9411b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSession(fileList, path, yearRegex):\n",
    "    sessionDict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in tqdm(fileList):\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        sessionInfo = soup.findAll('i') #info about session\n",
    "        title = soup.findAll('h2')\n",
    "        sessTitle = soup.findAll('title')[0].text\n",
    "        sessionName = re.findall(r'Session (.*) -', sessTitle, re.IGNORECASE)\n",
    "        if not sessionName: #try another way:\n",
    "            sessionName = re.findall(r'Session (.*),', sessTitle, re.IGNORECASE)\n",
    "        \n",
    "        if sessionName:\n",
    "            sessionTitle = sessionName[0]\n",
    "\n",
    "        for t in title:\n",
    "            titleStatement, titles = checkTitle(t.text)\n",
    "            if titleStatement:\n",
    "                sessionType = getSessionType(sessionInfo) #session type\n",
    "                sessionName = checkNames(sessionInfo[2:])#names are from 2. index. Check if it is a name. This is all names in the sessions\n",
    "                for n in sessionName: #loop through names, one session at a time\n",
    "                    names = getUni_and_Name(n.text)\n",
    "                    for p in names: #loop through one person at\n",
    "                        name = p[0]\n",
    "                        university = p[1]  \n",
    "                        sessionDict[index] = {'Year': year, 'Name': name, 'University': university,'Title': titles, 'SessionType': sessionType, 'SessionTitle': sessionTitle, 'SessionIndex': sessIndex}\n",
    "                        index += 1\n",
    "                    sessIndex += 1\n",
    "    return sessionDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcf4a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subCharacters(string): #subsitute characters\n",
    "    subFrom = [r'{\\\\AA}', r'\\\\\\'', r'\\\"{o}', r'\\\"o', r'\\\"O', '\\\"u', r'\\\"{u}', r'\\\"a', r'\\\"{a}', r'\\\"{A}', r'{\\\\o}', r'{\\\\O}', r'~{a}', r'\\\\v{z}', r'\\'{a}', r'\\\\v{c}', r'\\\\v{s}', r'\\'{c}', r'\\\\ü', r'\\\\c{c}', r'\\'{e}', r'\\\\~{n}', r'{\\\\ä}', r'\\\\ö', r'{\\\\ss}', r'\\\\v{e}', r'\\'I', r'\\\\v{r}', r'\\\\v{S}', r'\\\\\\^{e}', r'\\\\r{A}', r'\\\\c{S}', r'\\'{\\\\i}', r'{\\\\\" o}', r'\\\\\\^{o}', r'\\'{o}', r'\\\\`{e}', r'{\\'e}', r'\\\\o{}', r'\\\\v{Z}', r'\\'c', r'{ü}', r'\\\\c{s}'] \n",
    "    subTo = [r'Å', r\"'\", r'ö', r'ö', r'Ö', r'ü', r'ü', r'ä', r'ä', r'Ä', r'ø', r'Ø', r'ã', r'ž', r'á', r'č', r'š', 'ć', r'ü', r'ç', r'é', r'ñ', r'ä', r'ö', r'ß', r'ě', r'í', r'ř', r'Š', r'ê', r'Å', r'Ş', r'í', r'ö', r'ô', r'ó', r'è', r'é', r'ø', r'Ž', r'ć', r'ü', r'ş']\n",
    "\n",
    "    for i in range(0,len(subFrom)):\n",
    "        string = re.sub(subFrom[i], subTo[i], string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f709c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeString(stringList, list_): #remove several strings from a list\n",
    "    for i in stringList:\n",
    "        if i in list_:\n",
    "            list_.remove(i)\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07fb827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSpace(string):\n",
    "    string = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f2644",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n",
    "## Get Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133ee633",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakerDict = getSpeakers(speakers, speakerPath, r'Speakers(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9bffa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 172116/172116 [13:56<00:00, 205.79it/s]\n"
     ]
    }
   ],
   "source": [
    "presenterDict = getPresenters(presenters, presenterPath, r'Presenter(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e8050af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chairDict = getChair(chair, pages, chairPath, pagesPath, r'Chair(\\d+)', r'Pages(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c02e9bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 23.66it/s]\n"
     ]
    }
   ],
   "source": [
    "sessionNames = getSponsoringUnit_pages(pages, pagesPath, r'Pages(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83d8fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4506/4506 [02:02<00:00, 36.65it/s]\n"
     ]
    }
   ],
   "source": [
    "sessionDict = getSession(sessions, sessionPath, r'Session(\\d+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcf209",
   "metadata": {},
   "source": [
    "## Get dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08888cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker = pd.DataFrame.from_dict(speakerDict, orient = 'index') #invited speakers for file type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f52f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substiute Non-English characters with the true letters\n",
    "df_speaker['Name'] = df_speaker.Name.apply(subCharacters)\n",
    "df_speaker['University'] = df_speaker.University.apply(subCharacters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d277cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presenter = pd.DataFrame.from_dict(presenterDict, orient = 'index') #all presenters(including invited speakers) for file type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67629d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substiute Non-English characters with the true letters\n",
    "df_presenter['Name'] = df_presenter.Name.apply(subCharacters)\n",
    "df_presenter['University'] = df_presenter.University.apply(subCharacters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "952634ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "df_presenter = df_presenter.drop_duplicates(subset = ['Year', 'Name', 'Title', 'SessionTitle', 'SessionIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a03c3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with sponsoring unit, sessionTitle and Year\n",
    "sponsoringUnit = df_presenter[['Year', 'Name', 'SponsoringUnit', 'SessionTitle']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7211e5",
   "metadata": {},
   "source": [
    "Left join of presenters and invited speakers for file type 1. This gives a dataframe of all authors for presentations for the invited speakers. Sessions in the presenter dataframe is assigned to invited as sessionType, if it is in the invitedIndex, otherwise it is assigned as other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c02573af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join of df_speaker and df_presenter to get session index of invited sessions, and to to get all invited speakers\n",
    "invitedSpeakers = pd.merge(df_speaker, df_presenter[['Year', 'Name', 'AuthorIndex', 'SponsoringUnit', 'SessionTitle', 'SessionIndex']], on = ['Year', 'Name', 'SessionTitle'], how = 'left')\n",
    "invited_sessionIndex = invitedSpeakers.SessionIndex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d131fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invited sessions scraped: 17768\n",
      "Number of invited sessions with no SessionIndex: 846\n",
      "Number of invited sessions found in df_presenter: 16922\n",
      "Sum: 17768\n"
     ]
    }
   ],
   "source": [
    "#Checking data\n",
    "print(\"Number of invited sessions scraped:\", len(df_speaker))\n",
    "\n",
    "#number of invited speakers, which can't be found in df_presenter based on year and session title\n",
    "print(\"Number of invited sessions with no SessionIndex:\", len(invitedSpeakers[invitedSpeakers.SessionIndex.isna()])) \n",
    "\n",
    "#number of invited speakers found in df_presenter based on year and session title\n",
    "print(\"Number of invited sessions found in df_presenter:\", len(invitedSpeakers[~invitedSpeakers.SessionIndex.isna()].SessionIndex.unique()))\n",
    "\n",
    "print(\"Sum:\", len(invitedSpeakers[invitedSpeakers.SessionIndex.isna()]) + len(invitedSpeakers[~invitedSpeakers.SessionIndex.isna()].SessionIndex.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db1361b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attendees(authors) is all from df_presenters, where session index is not in invited_sessionindex\n",
    "attendees = df_presenter[~df_presenter.SessionIndex.isin(invitedSpeakers.SessionIndex)]\n",
    "\n",
    "#set session type as attendee for everyone\n",
    "attendees['SessionType'] = 'attendees'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90418080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set session type as invited for everyone\n",
    "invitedSpeakers['SessionType'] = 'invited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e33ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge attendees and invitedSpeakers\n",
    "allParticipants = pd.concat([attendees, invitedSpeakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "090b3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chair = pd.DataFrame.from_dict(chairDict, orient = 'index') #chair index for all years\n",
    "df_chair = df_chair.rename(columns={'University': \"Institution\"}) #rename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "631213d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessionOverview = pd.DataFrame.from_dict(sessionNames, orient = 'index') #overview of sessions for file type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a6808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session = pd.DataFrame.from_dict(sessionDict, orient = 'index') #all presenters(sessions) including invited speakers for file type 2\n",
    "\n",
    "#make space between names\n",
    "df_session['Name'] = df_session.Name.apply(makeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "460a30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author index is set to 0 as default for sessions before 2005\n",
    "#df_session['AuthorIndex'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "134325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates according to all attributes\n",
    "df_session = df_session.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0e74576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions = pd.merge(df_sessionOverview, df_session, on = ['SessionTitle', 'Year']) #merge overview and sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c53e6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with all presenters(authors) including invited speakers(and authors on their articles)\n",
    "all_presenters = pd.concat([allParticipants, df_sessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59bc5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set session type to 'presenter' if it is not invited\n",
    "all_presenters.loc[all_presenters['SessionType'] != 'invited', 'SessionType'] = 'attendee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cc5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new session index\n",
    "all_presenters['SessionIndex'] = np.where(all_presenters.SessionIndex.isnull(), all_presenters.SessionIndex + all_presenters.SessionIndex.max() + 1, all_presenters.SessionIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de0911d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>University</th>\n",
       "      <th>AuthorIndex</th>\n",
       "      <th>Title</th>\n",
       "      <th>SponsoringUnit</th>\n",
       "      <th>SessionTitle</th>\n",
       "      <th>SessionIndex</th>\n",
       "      <th>SessionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Prakash Giri</td>\n",
       "      <td>University of Nebraska - Lincoln</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Voltage-induced entropy change in complex oxid...</td>\n",
       "      <td>GMAG DMP DCOMP</td>\n",
       "      <td>S43.00007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Dhananjay Kumar</td>\n",
       "      <td>North Carolina Agricultural and Technical Stat...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Voltage-induced entropy change in complex oxid...</td>\n",
       "      <td>GMAG DMP DCOMP</td>\n",
       "      <td>S43.00007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>Christian Binek</td>\n",
       "      <td>University of Nebraska - Lincoln</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Voltage-induced entropy change in complex oxid...</td>\n",
       "      <td>GMAG DMP DCOMP</td>\n",
       "      <td>S43.00007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Chandler Benjamin</td>\n",
       "      <td>University of Wisconsin-Madison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Characterization of the Interfacial Adhesion f...</td>\n",
       "      <td>DPOLY</td>\n",
       "      <td>P47.00013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>John Springmann</td>\n",
       "      <td>University of Wisconsin-Madison</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Characterization of the Interfacial Adhesion f...</td>\n",
       "      <td>DPOLY</td>\n",
       "      <td>P47.00013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765007</th>\n",
       "      <td>4</td>\n",
       "      <td>S.N.Nakamura</td>\n",
       "      <td>Tohoku University, Sendai, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calculations of Single Particle time correlati...</td>\n",
       "      <td>DCP</td>\n",
       "      <td>Z35</td>\n",
       "      <td>630163.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765008</th>\n",
       "      <td>4</td>\n",
       "      <td>K.Nagamine</td>\n",
       "      <td>KEK-MSL, Tsukuba, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calculations of Single Particle time correlati...</td>\n",
       "      <td>DCP</td>\n",
       "      <td>Z35</td>\n",
       "      <td>630163.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765009</th>\n",
       "      <td>4</td>\n",
       "      <td>N. Kawamura</td>\n",
       "      <td>State University of New York at Albany, Albany NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calculations of Single Particle time correlati...</td>\n",
       "      <td>DCP</td>\n",
       "      <td>Z35</td>\n",
       "      <td>630163.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765010</th>\n",
       "      <td>4</td>\n",
       "      <td>Paul Moffatt</td>\n",
       "      <td>Department of Physics, University of Alberta, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calculations of Single Particle time correlati...</td>\n",
       "      <td>DCP</td>\n",
       "      <td>Z35</td>\n",
       "      <td>630164.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765011</th>\n",
       "      <td>4</td>\n",
       "      <td>Pierre-Nicholas Roy</td>\n",
       "      <td>Department of Chemistry, University of Alberta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calculations of Single Particle time correlati...</td>\n",
       "      <td>DCP</td>\n",
       "      <td>Z35</td>\n",
       "      <td>630164.0</td>\n",
       "      <td>attendee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2418837 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year                 Name  \\\n",
       "0          17         Prakash Giri   \n",
       "1          17      Dhananjay Kumar   \n",
       "2          17      Christian Binek   \n",
       "3          12    Chandler Benjamin   \n",
       "4          12      John Springmann   \n",
       "...       ...                  ...   \n",
       "1765007     4         S.N.Nakamura   \n",
       "1765008     4           K.Nagamine   \n",
       "1765009     4          N. Kawamura   \n",
       "1765010     4         Paul Moffatt   \n",
       "1765011     4  Pierre-Nicholas Roy   \n",
       "\n",
       "                                                University  AuthorIndex  \\\n",
       "0                         University of Nebraska - Lincoln          1.0   \n",
       "1        North Carolina Agricultural and Technical Stat...          2.0   \n",
       "2                         University of Nebraska - Lincoln          3.0   \n",
       "3                          University of Wisconsin-Madison          1.0   \n",
       "4                          University of Wisconsin-Madison          2.0   \n",
       "...                                                    ...          ...   \n",
       "1765007                   Tohoku University, Sendai, Japan          NaN   \n",
       "1765008                            KEK-MSL, Tsukuba, Japan          NaN   \n",
       "1765009  State University of New York at Albany, Albany NY          NaN   \n",
       "1765010  Department of Physics, University of Alberta, ...          NaN   \n",
       "1765011  Department of Chemistry, University of Alberta...          NaN   \n",
       "\n",
       "                                                     Title  SponsoringUnit  \\\n",
       "0        Voltage-induced entropy change in complex oxid...  GMAG DMP DCOMP   \n",
       "1        Voltage-induced entropy change in complex oxid...  GMAG DMP DCOMP   \n",
       "2        Voltage-induced entropy change in complex oxid...  GMAG DMP DCOMP   \n",
       "3        Characterization of the Interfacial Adhesion f...           DPOLY   \n",
       "4        Characterization of the Interfacial Adhesion f...           DPOLY   \n",
       "...                                                    ...             ...   \n",
       "1765007  Calculations of Single Particle time correlati...             DCP   \n",
       "1765008  Calculations of Single Particle time correlati...             DCP   \n",
       "1765009  Calculations of Single Particle time correlati...             DCP   \n",
       "1765010  Calculations of Single Particle time correlati...             DCP   \n",
       "1765011  Calculations of Single Particle time correlati...             DCP   \n",
       "\n",
       "        SessionTitle  SessionIndex SessionType  \n",
       "0          S43.00007           0.0    attendee  \n",
       "1          S43.00007           0.0    attendee  \n",
       "2          S43.00007           0.0    attendee  \n",
       "3          P47.00013           1.0    attendee  \n",
       "4          P47.00013           1.0    attendee  \n",
       "...              ...           ...         ...  \n",
       "1765007          Z35      630163.0    attendee  \n",
       "1765008          Z35      630163.0    attendee  \n",
       "1765009          Z35      630163.0    attendee  \n",
       "1765010          Z35      630164.0    attendee  \n",
       "1765011          Z35      630164.0    attendee  \n",
       "\n",
       "[2418837 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_presenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d87701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns\n",
    "all_presenters = all_presenters[['Year', 'Name', 'University', 'AuthorIndex', 'Title', 'SponsoringUnit', 'SessionIndex', 'SessionType']]\n",
    "\n",
    "all_presenters = all_presenters.rename(columns={'University': 'Institution', 'SponsoringUnit': 'Division'}) #rename column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb1202",
   "metadata": {},
   "source": [
    "Replace last 2 digits of year, to all 4 digits of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec1d1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearDict = {94 : 1994, 95 : 1995, 96 : 1996, 97 : 1997, 98 : 1998, 99 : 1999, 0 : 2000, 1 : 2001, 2 : 2002, 3 : 2003, 4 : 20004, 4 : 2004, 5: 2005, 6: 2006, 7: 2007, 8: 2008, 9: 2009, 10: 2010, 11: 2011, 12: 2012, 13: 2013, 14: 2014, 15: 2015, 16: 2016, 17: 2017, 18: 2018, 19: 2019, 20: 2020, 21: 2021, 22: 2022, 23: 2023}\n",
    "all_presenters = all_presenters.replace({'Year': yearDict}) #replace year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96e7f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 2418837\n",
      "Number of unique authors: 229992\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of authors:\", len(all_presenters))\n",
    "print(\"Number of unique authors:\", len(all_presenters.Name.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4880d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>AuthorIndex</th>\n",
       "      <th>Title</th>\n",
       "      <th>Division</th>\n",
       "      <th>SessionIndex</th>\n",
       "      <th>SessionType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>0</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>0</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>0</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>0</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>0</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>0</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>0</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>0</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "      <td>12677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "      <td>14176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "      <td>22300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>23232</td>\n",
       "      <td>23232</td>\n",
       "      <td>23231</td>\n",
       "      <td>23232</td>\n",
       "      <td>23231</td>\n",
       "      <td>23231</td>\n",
       "      <td>23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "      <td>24328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>26101</td>\n",
       "      <td>26101</td>\n",
       "      <td>26094</td>\n",
       "      <td>26101</td>\n",
       "      <td>26094</td>\n",
       "      <td>26094</td>\n",
       "      <td>26101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>25056</td>\n",
       "      <td>25056</td>\n",
       "      <td>24992</td>\n",
       "      <td>25056</td>\n",
       "      <td>24992</td>\n",
       "      <td>24992</td>\n",
       "      <td>25056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "      <td>35312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>33317</td>\n",
       "      <td>33317</td>\n",
       "      <td>33316</td>\n",
       "      <td>33317</td>\n",
       "      <td>33316</td>\n",
       "      <td>33316</td>\n",
       "      <td>33317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "      <td>36606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>35642</td>\n",
       "      <td>35642</td>\n",
       "      <td>35638</td>\n",
       "      <td>35642</td>\n",
       "      <td>35638</td>\n",
       "      <td>35638</td>\n",
       "      <td>35642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "      <td>37795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>40758</td>\n",
       "      <td>40758</td>\n",
       "      <td>40757</td>\n",
       "      <td>40758</td>\n",
       "      <td>40757</td>\n",
       "      <td>40757</td>\n",
       "      <td>40758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>43526</td>\n",
       "      <td>43526</td>\n",
       "      <td>43525</td>\n",
       "      <td>43526</td>\n",
       "      <td>43525</td>\n",
       "      <td>43525</td>\n",
       "      <td>43526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>46704</td>\n",
       "      <td>46704</td>\n",
       "      <td>46662</td>\n",
       "      <td>46704</td>\n",
       "      <td>46662</td>\n",
       "      <td>46662</td>\n",
       "      <td>46704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>46917</td>\n",
       "      <td>46917</td>\n",
       "      <td>46873</td>\n",
       "      <td>46917</td>\n",
       "      <td>46873</td>\n",
       "      <td>46873</td>\n",
       "      <td>46917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>47098</td>\n",
       "      <td>47098</td>\n",
       "      <td>47058</td>\n",
       "      <td>47098</td>\n",
       "      <td>47058</td>\n",
       "      <td>47058</td>\n",
       "      <td>47098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>49448</td>\n",
       "      <td>49448</td>\n",
       "      <td>49095</td>\n",
       "      <td>49448</td>\n",
       "      <td>49095</td>\n",
       "      <td>49095</td>\n",
       "      <td>49448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>52832</td>\n",
       "      <td>52832</td>\n",
       "      <td>52544</td>\n",
       "      <td>52832</td>\n",
       "      <td>52544</td>\n",
       "      <td>52544</td>\n",
       "      <td>52832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Institution  AuthorIndex   Title  Division  SessionIndex  \\\n",
       "Year                                                                     \n",
       "1996     849          849            0     849       849           849   \n",
       "1997  160881       160881            0  160881    160881        160881   \n",
       "1998  155331       155331            0  155331    155331        155331   \n",
       "2000  169100       169100            0  169100    169100        169100   \n",
       "2001  187386       187386            0  187386    187386        187386   \n",
       "2002  231063       231063            0  231063    231063        231063   \n",
       "2003  706649       706649            0  706649    706649        706649   \n",
       "2004  153753       153753            0  153753    153753        153753   \n",
       "2005   12677        12677        12677   12677     12677         12677   \n",
       "2006   14176        14176        14176   14176     14176         14176   \n",
       "2007   22300        22300        22300   22300     22300         22300   \n",
       "2008   23232        23232        23231   23232     23231         23231   \n",
       "2009   24328        24328        24328   24328     24328         24328   \n",
       "2010   26101        26101        26094   26101     26094         26094   \n",
       "2011   25056        25056        24992   25056     24992         24992   \n",
       "2012   35312        35312        35312   35312     35312         35312   \n",
       "2013   33317        33317        33316   33317     33316         33316   \n",
       "2014   36606        36606        36606   36606     36606         36606   \n",
       "2015   35642        35642        35638   35642     35638         35638   \n",
       "2016   37795        37795        37795   37795     37795         37795   \n",
       "2017   40758        40758        40757   40758     40757         40757   \n",
       "2018   43526        43526        43525   43526     43525         43525   \n",
       "2019   46704        46704        46662   46704     46662         46662   \n",
       "2020   46917        46917        46873   46917     46873         46873   \n",
       "2021   47098        47098        47058   47098     47058         47058   \n",
       "2022   49448        49448        49095   49448     49095         49095   \n",
       "2023   52832        52832        52544   52832     52544         52544   \n",
       "\n",
       "      SessionType  \n",
       "Year               \n",
       "1996          849  \n",
       "1997       160881  \n",
       "1998       155331  \n",
       "2000       169100  \n",
       "2001       187386  \n",
       "2002       231063  \n",
       "2003       706649  \n",
       "2004       153753  \n",
       "2005        12677  \n",
       "2006        14176  \n",
       "2007        22300  \n",
       "2008        23232  \n",
       "2009        24328  \n",
       "2010        26101  \n",
       "2011        25056  \n",
       "2012        35312  \n",
       "2013        33317  \n",
       "2014        36606  \n",
       "2015        35642  \n",
       "2016        37795  \n",
       "2017        40758  \n",
       "2018        43526  \n",
       "2019        46704  \n",
       "2020        46917  \n",
       "2021        47098  \n",
       "2022        49448  \n",
       "2023        52832  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_presenters.groupby(['Year']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10700e29",
   "metadata": {},
   "source": [
    "Now all presenters are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cb34400",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_presenters.to_pickle(\"Files/Dataframes/researchers_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

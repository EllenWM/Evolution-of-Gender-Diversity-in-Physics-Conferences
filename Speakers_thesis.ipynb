{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1349fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from iteration_utilities import duplicates\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74adae4",
   "metadata": {},
   "source": [
    "# Functions and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04aad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFile(fileList, file): #remove file from list of files. file as string \n",
    "    if file in fileList:\n",
    "        fileList.remove(file)\n",
    "        \n",
    "    return fileList  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c719d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakerPath = \"Files/InvitedSpeakers\"\n",
    "presenterPath = \"Files/Presenters\"\n",
    "chairPath = \"Files/ChairIndex\"\n",
    "pagesPath = \"Files/Pages\"\n",
    "sessionPath = \"Files/Sessions\"\n",
    "\n",
    "speakers = removeFile(os.listdir(speakerPath), '.DS_Store') #invited speakers for 2005-2023\n",
    "presenters = removeFile(os.listdir(presenterPath),'.DS_Store')  #all presenters for 2005-2023\n",
    "chair = removeFile(os.listdir(chairPath), '.DS_Store') #chair index for 2005-2023\n",
    "pages = removeFile(os.listdir(pagesPath), '.DS_Store') #pages showing overview of sessions for 1994-2004\n",
    "sessions = removeFile(os.listdir(sessionPath), '.DS_Store') #showing overview of subsessions for 1994-2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62706c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoupFromFile(path, file): #get soup from file\n",
    "    soup = BeautifulSoup(open(path + '/' + file))\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a53174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYear(regex, file): #get year from name on file\n",
    "    year = int(re.findall(regex, file)[0])\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343053d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from the other notebook, instead of repeating it\n",
    "def getText(soup, regex, find_type, attribute): #attribute as string\n",
    "    text_list = []\n",
    "    \n",
    "    if attribute == 'text':\n",
    "        for t in soup.find_all(find_type, string = re.compile(regex, re.IGNORECASE)):\n",
    "            text_list.append(t.text)\n",
    "    else:\n",
    "        for t in soup.find_all(find_type, attrs = {attribute: re.compile(regex, re.IGNORECASE)}):\n",
    "            text_list.append(t.text)\n",
    " \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f873adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseName(name): #reverse name, so first name is first\n",
    "    if name == 'TBD, ':\n",
    "        reversedName = name\n",
    "    else:\n",
    "        nameGroup = re.findall(r'(.*), (.*) ', name)[0] #first name and last name as group\n",
    "        reversedName = nameGroup[1] + \" \" + nameGroup[0] #reverse name\n",
    "        \n",
    "    return reversedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a6fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speakerInfo(soup, year, dict_, index): #get name, university and title of invited speaker from file. Page type 1\n",
    "    speakerInfo = soup.table.findAll('tr')\n",
    "    for i in speakerInfo:\n",
    "        inv_name = i.strong.text #invited speakers\n",
    "        name = reverseName(inv_name) #name reversed, so first name is first\n",
    "        university = getText(i, r'2', 'font', 'size')[0] #university/department\n",
    "        presentationInfo = i.findAll('b')[0].text #info about presentation/abstract\n",
    "        sessionTitle = re.findall(r'Session (.*) ', presentationInfo)[0] #get sessionTitle\n",
    "        title = re.findall(r'\\n(.*)', presentationInfo)[0] #get title of presentation/article\n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university, 'Title': title, 'SessionTitle': sessionTitle}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897884c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSessionTitle(soup): #for presenter, of file type 1\n",
    "    titleText = soup.findAll('title')\n",
    "    if titleText:\n",
    "        title = re.findall(r'Event - (.*)', titleText[0].text)[0]\n",
    "    else:\n",
    "        title = 'Unknown'\n",
    "        \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c579a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringUnit(soup): #find sponsoring unit for sessions(speakers). Works for file type 1.\n",
    "    findSponsor = soup.find(string = re.compile(r'Sponsoring'))  #compile sponsor\n",
    "    if findSponsor:\n",
    "        sponsor = re.findall(r':.*\\n(.*)', findSponsor)[0]\n",
    "    else:\n",
    "        sponsor = 'None'\n",
    "    return sponsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39039257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringDict(soup, year, dict_, index): #get sponsoring unit as dict\n",
    "    linkText = soup.find_all('a') #find text about link\n",
    "    for t in linkText:\n",
    "        sponsor = re.findall(r'\\n (.*):', t.previous)\n",
    "        if sponsor:\n",
    "            sponsoringUnit = sponsor[0]\n",
    "            session = re.findall(r'Session (.*).', t.previous.previous)[0]\n",
    " \n",
    "        else:\n",
    "            sponsoringUnit = 'None'\n",
    "            session = 'Unknown'\n",
    "        \n",
    "        dict_[index] = {'Year': year, 'SessionTitle': session, 'SponsoringUnit': sponsoringUnit}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92dbcc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findText(soup, findType, attribute): #attribute as dict. Get text base on findType and attribute\n",
    "    text = soup.findAll(findType, attrs = attribute)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6138b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbstractInfo(soup): #for file type 1. Get name for presentation/abstract\n",
    "    abstractInfo = soup.findAll('h3')\n",
    "    if abstractInfo:\n",
    "        for i in abstractInfo:\n",
    "            if i.next == 'Abstract: ':\n",
    "                sessionTitle = i.next.next.text\n",
    "            else: \n",
    "                sessionTitle = \"Not found\"\n",
    "    else:\n",
    "        sessionTitle = \"Not found\"\n",
    "    return sessionTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58e2412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresenterInfo(soup, year, dict_, index, sessionIndex): #get info from presenter and session, page type 1\n",
    "    names = [] #for all names found\n",
    "    #authors = [] #for saving authors\n",
    "    authorCount = 0\n",
    "    title = getSessionTitle(soup) #get title of session\n",
    "    presenterInfo = findText(soup, 'span', {'class': 'largernormal'}) #get presenterInfo\n",
    "    sessionTitle = getAbstractInfo(soup)\n",
    "    sponsoringUnit = getSponsoringUnit(soup)\n",
    "    for i in presenterInfo:\n",
    "        name = i.text\n",
    "        author = re.findall(r'^\\n(.*)\\n', name)[0]\n",
    "        if author:\n",
    "            authorCount += 1\n",
    "            uniName = re.findall(r'\\((.*)\\)', name)\n",
    "            if not uniName:\n",
    "                university = 'Unknown'\n",
    "            else:\n",
    "                university = uniName[0]\n",
    "            #authors.append(author)\n",
    "            \n",
    "            dict_[index] = {'Year': year, 'Name': author, 'University': university, 'AuthorIndex': authorCount, \n",
    "                            'Title': title, 'SponsoringUnit': sponsoringUnit, 'SessionTitle': sessionTitle, 'SessionIndex': sessionIndex}\n",
    "            index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf2a5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitName(nameInfo, splitBy): #splits names into name and university\n",
    "    nameSplit = nameInfo.split(splitBy)\n",
    "    name = nameSplit[0]\n",
    "    if len(nameSplit) == 2: #if name and university is written\n",
    "        university = nameSplit[1]\n",
    "        university = re.sub(r' \\xa0', r'', university)\n",
    "        university = re.sub(r' \\)', r'', university)\n",
    "    else:\n",
    "        university = 'Unknown'\n",
    "    \n",
    "    return name, university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d1c0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkString(string, regex):\n",
    "    if re.findall(regex, string):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05e932f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNames(nameList): #check if string is a name\n",
    "    names = []\n",
    "    for n in nameList:\n",
    "        name = n.get_text()\n",
    "        if name != '' and name != 'both' and name != 'smaller':\n",
    "            if not checkString(name, r'session') and not checkString(name, r'Room') and not checkString(name, r'\\[.*\\]') and not checkString(name, r'\\n\\n'):\n",
    "                names.append(n)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b79183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTitle(titleString): #check if string is title, and return title and whether it's a title or not\n",
    "    title = re.findall(r'\\[.*\\] (.*)', titleString)\n",
    "    if title: #check if there is a title\n",
    "        if title[0] != 'Break': #if title isn't break\n",
    "            return True, title[0]\n",
    "        else:\n",
    "            return False, title\n",
    "    else:\n",
    "        return False, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "539f84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkUniversity(string): #check if string includes university (if it is inside pharanthesis)\n",
    "    if re.findall('\\(.*\\)', string):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e2ac2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameInfo(string): #return university and name from string (if university is inside pharanthesis)\n",
    "    university = re.findall(r'\\((.*)\\)', string)[0]\n",
    "    name = re.findall(r'(.*)\\(', string)[0]\n",
    "    name = re.sub(' ', '', name)\n",
    "\n",
    "    return university, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da31deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUni_and_Name(string):\n",
    "    nameInfo = []\n",
    "    names = re.split(r',\\s*(?![^()]*\\))', string)\n",
    "    \n",
    "    noUniversity = [] \n",
    "    universityList = []\n",
    "    \n",
    "    for i in names: #loop through all names\n",
    "        if checkUniversity(i): #if name is together with a university\n",
    "            university, name = getNameInfo(i) #get name and university\n",
    "            nameInfo.append((name, university)) #add name and university to set\n",
    "            \n",
    "            universityList.extend(repeat(university, len(noUniversity))) #append university the number of times, a name don't have a university\n",
    "            noUniInfo = list(zip(noUniversity, universityList)) #assign name without university to university\n",
    "            nameInfo += noUniInfo #add name and university to list\n",
    "            \n",
    "            noUniversity = [] #reset names without university\n",
    "            \n",
    "        else:\n",
    "            noUniversity.append(i)\n",
    "            \n",
    "    return nameInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "687b5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakers(fileList, path, yearRegex): #get invited speakers to dict(with their info). Page type 1\n",
    "    speaker_dict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in fileList:\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        speaker_dict, index  = speakerInfo(soup, year, speaker_dict, index)\n",
    "        \n",
    "    return speaker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "100ac456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresenters(fileList, path, yearRegex): #page type 1\n",
    "    presenter_dict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in tqdm(fileList):\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        presenter_dict, index = getPresenterInfo(soup, year, presenter_dict, index,  sessIndex)\n",
    "        sessIndex += 1\n",
    "        \n",
    "    return presenter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f92d6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChairIndex1(soup, year, dict_, index):#for file type 1\n",
    "    chairNames = findText(soup, 'td', {'align': None, 'valign': 'top'})\n",
    "    for n in chairNames:\n",
    "        name, university = splitName(n.text, ',')\n",
    "        \n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university} #add year, name and university to dictionary\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93f745fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getChairIndex2(soup, year, dict_, index):#for file type 2\n",
    "def getChairIndex2(soup, year, dict_, index):#for file type 2\n",
    "    chairNames = re.findall(r'Chair: (.*)', str(soup))\n",
    "    for n in chairNames:\n",
    "        name, university = splitName(n, ',')\n",
    "        dict_[index] = {'Year': year, 'Name': name, 'University': university}\n",
    "        index += 1\n",
    "        \n",
    "    return dict_, index\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48ebae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChair(fileList1, fileList2, path1, path2, yearRegex1, yearRegex2): #get chairIndex for type 1 and 2 files\n",
    "    chair_dict = {}\n",
    "    index = 0\n",
    "    for file in fileList1:\n",
    "        soup = getSoupFromFile(path1, file)\n",
    "        year = getYear(yearRegex1, file)\n",
    "        chair_dict, index = getChairIndex1(soup, year, chair_dict, index)\n",
    "    \n",
    "    for file in fileList2:\n",
    "        soup = getSoupFromFile(path2, file)\n",
    "        year = getYear(yearRegex2, file)\n",
    "        chair_dict, index = getChairIndex2(soup, year, chair_dict, index)\n",
    "    \n",
    "    return chair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9f73896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSessionType(info): #get session type\n",
    "    sessionType = re.findall(r'<i>(.*) session', str(info))[0].lower()\n",
    "    \n",
    "    return sessionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0af84139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSponsoringUnit_pages(fileList, path, yearRegex): #get sponsoring unit for file type 2, from pages\n",
    "    sponsoringDict = {}\n",
    "    index = 0\n",
    "    for file in tqdm(fileList): \n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        speaker_dict, index  = getSponsoringDict(soup, year, sponsoringDict, index)\n",
    "    \n",
    "    return sponsoringDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9411b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSession(fileList, path, yearRegex):\n",
    "    sessionDict = {}\n",
    "    index = 0\n",
    "    sessIndex = 0\n",
    "    for file in tqdm(fileList):\n",
    "        soup = getSoupFromFile(path, file)\n",
    "        year = getYear(yearRegex, file)\n",
    "        sessionInfo = soup.findAll('i') #info about session\n",
    "        title = soup.findAll('h2')\n",
    "        sessTitle = soup.findAll('title')[0].text\n",
    "        sessionName = re.findall(r'Session (.*) -', sessTitle, re.IGNORECASE)\n",
    "        if not sessionName: #try another way:\n",
    "            sessionName = re.findall(r'Session (.*),', sessTitle, re.IGNORECASE)\n",
    "        \n",
    "        if sessionName:\n",
    "            sessionTitle = sessionName[0]\n",
    "\n",
    "        for t in title:\n",
    "            titleStatement, titles = checkTitle(t.text)\n",
    "            if titleStatement:\n",
    "                sessionType = getSessionType(sessionInfo) #session type\n",
    "                sessionName = checkNames(sessionInfo[2:])#names are from 2. index. Check if it is a name. This is all names in the sessions\n",
    "                for n in sessionName: #loop through names, one session at a time\n",
    "                    names = getUni_and_Name(n.text)\n",
    "                    for p in names: #loop through one person at\n",
    "                        name = p[0]\n",
    "                        university = p[1]  \n",
    "                        sessionDict[index] = {'Year': year, 'Name': name, 'University': university,'Title': titles, 'SessionType': sessionType, 'SessionTitle': sessionTitle, 'SessionIndex': sessIndex}\n",
    "                        index += 1\n",
    "                    sessIndex += 1\n",
    "    return sessionDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcf4a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subCharacters(string): #subsitute characters\n",
    "    subFrom = [r'{\\\\AA}', r'\\\\\\'', r'\\\"{o}', r'\\\"o', r'\\\"O', '\\\"u', r'\\\"{u}', r'\\\"a', r'\\\"{a}', r'\\\"{A}', r'{\\\\o}', r'{\\\\O}', r'~{a}', r'\\\\v{z}', r'\\'{a}', r'\\\\v{c}', r'\\\\v{s}', r'\\'{c}', r'\\\\ü', r'\\\\c{c}', r'\\'{e}', r'\\\\~{n}', r'{\\\\ä}', r'\\\\ö', r'{\\\\ss}', r'\\\\v{e}', r'\\'I', r'\\\\v{r}', r'\\\\v{S}', r'\\\\\\^{e}', r'\\\\r{A}', r'\\\\c{S}', r'\\'{\\\\i}', r'{\\\\\" o}', r'\\\\\\^{o}', r'\\'{o}', r'\\\\`{e}', r'{\\'e}', r'\\\\o{}', r'\\\\v{Z}', r'\\'c', r'{ü}', r'\\\\c{s}'] \n",
    "    subTo = [r'Å', r\"'\", r'ö', r'ö', r'Ö', r'ü', r'ü', r'ä', r'ä', r'Ä', r'ø', r'Ø', r'ã', r'ž', r'á', r'č', r'š', 'ć', r'ü', r'ç', r'é', r'ñ', r'ä', r'ö', r'ß', r'ě', r'í', r'ř', r'Š', r'ê', r'Å', r'Ş', r'í', r'ö', r'ô', r'ó', r'è', r'é', r'ø', r'Ž', r'ć', r'ü', r'ş']\n",
    "\n",
    "    for i in range(0,len(subFrom)):\n",
    "        string = re.sub(subFrom[i], subTo[i], string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f709c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeString(stringList, list_): #remove several strings from a list\n",
    "    for i in stringList:\n",
    "        if i in list_:\n",
    "            list_.remove(i)\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07fb827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSpace(string):\n",
    "    string = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f2644",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n",
    "## Get Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "133ee633",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakerDict = getSpeakers(speakers, speakerPath, r'Speakers(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9bffa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 172116/172116 [13:53<00:00, 206.48it/s]\n"
     ]
    }
   ],
   "source": [
    "presenterDict = getPresenters(presenters, presenterPath, r'Presenter(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e8050af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chairDict = getChair(chair, pages, chairPath, pagesPath, r'Chair(\\d+)', r'Pages(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c02e9bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 29.85it/s]\n"
     ]
    }
   ],
   "source": [
    "sessionNames = getSponsoringUnit_pages(pages, pagesPath, r'Pages(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83d8fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4506/4506 [01:57<00:00, 38.19it/s]\n"
     ]
    }
   ],
   "source": [
    "sessionDict = getSession(sessions, sessionPath, r'Session(\\d+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcf209",
   "metadata": {},
   "source": [
    "## Get dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08888cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker = pd.DataFrame.from_dict(speakerDict, orient = 'index') #invited speakers for file type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f52f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substiute Non-English characters with the true letters\n",
    "df_speaker['Name'] = df_speaker.Name.apply(subCharacters)\n",
    "df_speaker['University'] = df_speaker.University.apply(subCharacters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d277cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presenter = pd.DataFrame.from_dict(presenterDict, orient = 'index') #all presenters(including invited speakers) for file type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67629d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substiute Non-English characters with the true letters\n",
    "df_presenter['Name'] = df_presenter.Name.apply(subCharacters)\n",
    "df_presenter['University'] = df_presenter.University.apply(subCharacters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "952634ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presenter = df_presenter.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a03c3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with sponsoring unit, sessionTitle and Year\n",
    "sponsoringUnit = df_presenter[['Year', 'Name', 'SponsoringUnit', 'SessionTitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "35ada330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sponsoring unit to df_speaker\n",
    "df_speaker = pd.merge(df_speaker, sponsoringUnit, on = ['Year', 'SessionTitle', 'Name'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7211e5",
   "metadata": {},
   "source": [
    "Inner join of presenters and invited speakers for file type 1. This gives a dataframe of all authors for presentations for the invited speakers. Sessions in the presenter dataframe is assigned to invited as sessionType, if it is in the invitedIndex, otherwise it is assigned as other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5f742d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one df for all authors for file type 1\n",
    "invitedIndex = df_presenter.merge(df_speaker, how = 'inner', on = ['Year', 'SessionTitle']).index \n",
    "\n",
    "df_presenter['SessionType'] = np.where(df_presenter.index.isin(invitedIndex), 'invited', 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7ba00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all presenters(without invited sessions)\n",
    "df_participants = df_presenter[df_presenter.SessionType != 'invited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44d9018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sessiontype to invited speakers(for merging later)\n",
    "df_speaker['SessionType'] = 'invited'\n",
    "\n",
    "df_speaker['AuthorIndex'] = 1 #author index is set to 1 as default for invited speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f89a064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge df_presenter and df_speaker\n",
    "participants = pd.concat([df_participants, df_speaker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b44676a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chair = pd.DataFrame.from_dict(chairDict, orient = 'index') #chair index for all years\n",
    "df_chair = df_chair.rename(columns={'University': \"Institution\"}) #rename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "631213d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessionOverview = pd.DataFrame.from_dict(sessionNames, orient = 'index') #overview of sessions for file type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a6808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session = pd.DataFrame.from_dict(sessionDict, orient = 'index') #all presenters(sessions) including invited speakers for file type 2\n",
    "\n",
    "#make space between names\n",
    "df_session['Name'] = df_session.Name.apply(makeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "460a30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author index is set to 0 as default for sessions before 2005\n",
    "df_session['AuthorIndex'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "134325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates according to all attributes\n",
    "df_session = df_session.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f0e74576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions = pd.merge(df_sessionOverview, df_session, on = ['SessionTitle', 'Year']) #merge overview and sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c53e6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with all presenters(authors) including invited speakers(and authors on their articles)\n",
    "all_presenters = pd.concat([participants, df_sessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "59bc5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set session type to 'presenter' if it is not invited\n",
    "all_presenters.loc[all_presenters['SessionType'] != 'invited', 'SessionType'] = 'attendee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0cc5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new session index\n",
    "all_presenters['SessionIndex'] = np.where(all_presenters.SessionIndex.isnull(), all_presenters.SessionIndex + all_presenters.SessionIndex.max() + 1, all_presenters.SessionIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3d87701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns\n",
    "all_presenters = all_presenters[['Year', 'Name', 'University', 'AuthorIndex', 'Title', 'SponsoringUnit', 'SessionIndex', 'SessionType']]\n",
    "\n",
    "all_presenters = all_presenters.rename(columns={'University': 'Institution', 'SponsoringUnit': 'Division'}) #rename column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb1202",
   "metadata": {},
   "source": [
    "Replace last 2 digits of year, to all 4 digits of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ec1d1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearDict = {94 : 1994, 95 : 1995, 96 : 1996, 97 : 1997, 98 : 1998, 99 : 1999, 0 : 2000, 1 : 2001, 2 : 2002, 3 : 2003, 4 : 20004, 4 : 2004, 5: 2005, 6: 2006, 7: 2007, 8: 2008, 9: 2009, 10: 2010, 11: 2011, 12: 2012, 13: 2013, 14: 2014, 15: 2015, 16: 2016, 17: 2017, 18: 2018, 19: 2019, 20: 2020, 21: 2021, 22: 2022, 23: 2023}\n",
    "all_presenters = all_presenters.replace({'Year': yearDict}) #replace year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "96e7f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 2464377\n",
      "Number of unique authors: 223948\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of authors:\", len(all_presenters))\n",
    "print(\"Number of unique authors:\", len(all_presenters.Name.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4880d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>AuthorIndex</th>\n",
       "      <th>Title</th>\n",
       "      <th>Division</th>\n",
       "      <th>SessionIndex</th>\n",
       "      <th>SessionType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "      <td>160881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "      <td>155331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "      <td>169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "      <td>187386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "      <td>231063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "      <td>706649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "      <td>153753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>12476</td>\n",
       "      <td>12476</td>\n",
       "      <td>12476</td>\n",
       "      <td>12476</td>\n",
       "      <td>12476</td>\n",
       "      <td>11704</td>\n",
       "      <td>12476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>13884</td>\n",
       "      <td>13884</td>\n",
       "      <td>13884</td>\n",
       "      <td>13884</td>\n",
       "      <td>13884</td>\n",
       "      <td>13133</td>\n",
       "      <td>13884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>21512</td>\n",
       "      <td>21512</td>\n",
       "      <td>21512</td>\n",
       "      <td>21512</td>\n",
       "      <td>21512</td>\n",
       "      <td>20783</td>\n",
       "      <td>21512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>22296</td>\n",
       "      <td>22296</td>\n",
       "      <td>22296</td>\n",
       "      <td>22296</td>\n",
       "      <td>22295</td>\n",
       "      <td>21561</td>\n",
       "      <td>22296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>23437</td>\n",
       "      <td>23437</td>\n",
       "      <td>23437</td>\n",
       "      <td>23437</td>\n",
       "      <td>23437</td>\n",
       "      <td>22617</td>\n",
       "      <td>23437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>25031</td>\n",
       "      <td>25031</td>\n",
       "      <td>25031</td>\n",
       "      <td>25031</td>\n",
       "      <td>25024</td>\n",
       "      <td>24213</td>\n",
       "      <td>25031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>23981</td>\n",
       "      <td>23981</td>\n",
       "      <td>23981</td>\n",
       "      <td>23981</td>\n",
       "      <td>23917</td>\n",
       "      <td>23153</td>\n",
       "      <td>23981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>33649</td>\n",
       "      <td>33649</td>\n",
       "      <td>33649</td>\n",
       "      <td>33649</td>\n",
       "      <td>33649</td>\n",
       "      <td>32755</td>\n",
       "      <td>33649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>31834</td>\n",
       "      <td>31834</td>\n",
       "      <td>31834</td>\n",
       "      <td>31834</td>\n",
       "      <td>31833</td>\n",
       "      <td>30925</td>\n",
       "      <td>31834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>34927</td>\n",
       "      <td>34927</td>\n",
       "      <td>34927</td>\n",
       "      <td>34927</td>\n",
       "      <td>34927</td>\n",
       "      <td>34017</td>\n",
       "      <td>34927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>34176</td>\n",
       "      <td>34176</td>\n",
       "      <td>34176</td>\n",
       "      <td>34176</td>\n",
       "      <td>34172</td>\n",
       "      <td>33238</td>\n",
       "      <td>34176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>35980</td>\n",
       "      <td>35980</td>\n",
       "      <td>35980</td>\n",
       "      <td>35980</td>\n",
       "      <td>35980</td>\n",
       "      <td>35057</td>\n",
       "      <td>35980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>38922</td>\n",
       "      <td>38922</td>\n",
       "      <td>38922</td>\n",
       "      <td>38922</td>\n",
       "      <td>38921</td>\n",
       "      <td>37942</td>\n",
       "      <td>38922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>53222</td>\n",
       "      <td>53222</td>\n",
       "      <td>53222</td>\n",
       "      <td>53222</td>\n",
       "      <td>53221</td>\n",
       "      <td>51262</td>\n",
       "      <td>53222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>57040</td>\n",
       "      <td>57040</td>\n",
       "      <td>57040</td>\n",
       "      <td>57040</td>\n",
       "      <td>56998</td>\n",
       "      <td>54892</td>\n",
       "      <td>57040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>57329</td>\n",
       "      <td>57329</td>\n",
       "      <td>57329</td>\n",
       "      <td>57329</td>\n",
       "      <td>57285</td>\n",
       "      <td>55171</td>\n",
       "      <td>57329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>57352</td>\n",
       "      <td>57352</td>\n",
       "      <td>57352</td>\n",
       "      <td>57352</td>\n",
       "      <td>57312</td>\n",
       "      <td>55020</td>\n",
       "      <td>57352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>58922</td>\n",
       "      <td>58922</td>\n",
       "      <td>58922</td>\n",
       "      <td>58922</td>\n",
       "      <td>58569</td>\n",
       "      <td>56851</td>\n",
       "      <td>58922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>63395</td>\n",
       "      <td>63395</td>\n",
       "      <td>63395</td>\n",
       "      <td>63395</td>\n",
       "      <td>63107</td>\n",
       "      <td>61435</td>\n",
       "      <td>63395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Institution  AuthorIndex   Title  Division  SessionIndex  \\\n",
       "Year                                                                     \n",
       "1996     849          849          849     849       849           849   \n",
       "1997  160881       160881       160881  160881    160881        160881   \n",
       "1998  155331       155331       155331  155331    155331        155331   \n",
       "2000  169100       169100       169100  169100    169100        169100   \n",
       "2001  187386       187386       187386  187386    187386        187386   \n",
       "2002  231063       231063       231063  231063    231063        231063   \n",
       "2003  706649       706649       706649  706649    706649        706649   \n",
       "2004  153753       153753       153753  153753    153753        153753   \n",
       "2005   12476        12476        12476   12476     12476         11704   \n",
       "2006   13884        13884        13884   13884     13884         13133   \n",
       "2007   21512        21512        21512   21512     21512         20783   \n",
       "2008   22296        22296        22296   22296     22295         21561   \n",
       "2009   23437        23437        23437   23437     23437         22617   \n",
       "2010   25031        25031        25031   25031     25024         24213   \n",
       "2011   23981        23981        23981   23981     23917         23153   \n",
       "2012   33649        33649        33649   33649     33649         32755   \n",
       "2013   31834        31834        31834   31834     31833         30925   \n",
       "2014   34927        34927        34927   34927     34927         34017   \n",
       "2015   34176        34176        34176   34176     34172         33238   \n",
       "2016   35980        35980        35980   35980     35980         35057   \n",
       "2017   38922        38922        38922   38922     38921         37942   \n",
       "2018   53222        53222        53222   53222     53221         51262   \n",
       "2019   57040        57040        57040   57040     56998         54892   \n",
       "2020   57329        57329        57329   57329     57285         55171   \n",
       "2021   57352        57352        57352   57352     57312         55020   \n",
       "2022   58922        58922        58922   58922     58569         56851   \n",
       "2023   63395        63395        63395   63395     63107         61435   \n",
       "\n",
       "      SessionType  \n",
       "Year               \n",
       "1996          849  \n",
       "1997       160881  \n",
       "1998       155331  \n",
       "2000       169100  \n",
       "2001       187386  \n",
       "2002       231063  \n",
       "2003       706649  \n",
       "2004       153753  \n",
       "2005        12476  \n",
       "2006        13884  \n",
       "2007        21512  \n",
       "2008        22296  \n",
       "2009        23437  \n",
       "2010        25031  \n",
       "2011        23981  \n",
       "2012        33649  \n",
       "2013        31834  \n",
       "2014        34927  \n",
       "2015        34176  \n",
       "2016        35980  \n",
       "2017        38922  \n",
       "2018        53222  \n",
       "2019        57040  \n",
       "2020        57329  \n",
       "2021        57352  \n",
       "2022        58922  \n",
       "2023        63395  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_presenters.groupby(['Year']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10700e29",
   "metadata": {},
   "source": [
    "Now all presenters are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7cb34400",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_presenters.to_pickle(\"Files/Dataframes/researchers_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
